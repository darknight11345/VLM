SLURM GPU devices: 0
INFO 08-08 12:17:52 [__init__.py:235] Automatically detected platform cuda.
INFO 08-08 12:18:16 [config.py:1604] Using max model len 32000
INFO 08-08 12:18:20 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=16384.

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/Pixtral-Finetune/inference_scripts/all_experiments_mistral.py", line 311, in <module>
    llm = LLM(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/entrypoints/llm.py", line 273, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 497, in from_engine_args
    return engine_cls.from_vllm_config(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py", line 126, in from_vllm_config
    return cls(vllm_config=vllm_config,
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py", line 88, in __init__
    self.tokenizer = init_tokenizer_from_configs(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizer_group.py", line 111, in init_tokenizer_from_configs
    return TokenizerGroup(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizer_group.py", line 24, in __init__
    self.tokenizer = get_tokenizer(self.tokenizer_id, **tokenizer_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizer.py", line 227, in get_tokenizer
    tokenizer = MistralTokenizer.from_pretrained(str(tokenizer_name),
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizers/mistral.py", line 254, in from_pretrained
    from mistral_common.tokens.tokenizers.mistral import (
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/mistral.py", line 16, in <module>
    from mistral_common.protocol.instruct.normalize import InstructRequestNormalizer, normalizer_for_tokenizer_version
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/protocol/instruct/normalize.py", line 22, in <module>
    from mistral_common.tokens.tokenizers.base import InstructRequestType, TokenizerVersion
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/base.py", line 22, in <module>
    from mistral_common.tokens.tokenizers.image import ImageEncoder
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/image.py", line 19, in <module>
    import cv2
AttributeError: _ARRAY_API not found
/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.
  warnings.warn(
WARNING 08-08 12:18:22 [__init__.py:2899] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized
INFO 08-08 12:18:28 [__init__.py:235] Automatically detected platform cuda.
INFO 08-08 12:18:30 [core.py:572] Waiting for init message from front-end.
INFO 08-08 12:18:30 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='/pfs/work9/workspace/scratch/ul_swv79-pixtral/pixtral-12b/', speculative_config=None, tokenizer='/pfs/work9/workspace/scratch/ul_swv79-pixtral/pixtral-12b/', skip_tokenizer_init=False, tokenizer_mode=mistral, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/pfs/work9/workspace/scratch/ul_swv79-pixtral/pixtral-12b/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
INFO 08-08 12:18:41 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "<string>", line 1, in <module>
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 623, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 441, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 77, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
    self._init_executor()
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
    self.collective_rpc("init_device")
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/utils/__init__.py", line 2985, in run_method
    return func(*args, **kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 603, in init_device
    self.worker.init_device()  # type: ignore
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 189, in init_device
    self.model_runner: GPUModelRunner = GPUModelRunner(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 146, in __init__
    encoder_compute_budget, encoder_cache_size = compute_encoder_budget(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/core/encoder_cache_manager.py", line 199, in compute_encoder_budget
    ) = _compute_encoder_budget_multimodal(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/core/encoder_cache_manager.py", line 229, in _compute_encoder_budget_multimodal
    .get_max_tokens_per_item_by_nonzero_modality(model_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 153, in get_max_tokens_per_item_by_nonzero_modality
    mm_limits = self.get_mm_limits_per_prompt(model_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 206, in get_mm_limits_per_prompt
    processor = self.create_processor(model_config, disable_cache=False)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 270, in create_processor
    tokenizer = cached_tokenizer_from_config(model_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizer.py", line 295, in cached_tokenizer_from_config
    return cached_get_tokenizer(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizer.py", line 227, in get_tokenizer
    tokenizer = MistralTokenizer.from_pretrained(str(tokenizer_name),
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/tokenizers/mistral.py", line 254, in from_pretrained
    from mistral_common.tokens.tokenizers.mistral import (
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/mistral.py", line 16, in <module>
    from mistral_common.protocol.instruct.normalize import InstructRequestNormalizer, normalizer_for_tokenizer_version
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/protocol/instruct/normalize.py", line 22, in <module>
    from mistral_common.tokens.tokenizers.base import InstructRequestType, TokenizerVersion
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/base.py", line 22, in <module>
    from mistral_common.tokens.tokenizers.image import ImageEncoder
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/image.py", line 19, in <module>
    import cv2
[rank0]: AttributeError: _ARRAY_API not found
/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
ERROR 08-08 12:18:45 [core.py:632] EngineCore failed to start.
ERROR 08-08 12:18:45 [core.py:632] Traceback (most recent call last):
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 623, in run_engine_core
ERROR 08-08 12:18:45 [core.py:632]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 441, in __init__
ERROR 08-08 12:18:45 [core.py:632]     super().__init__(vllm_config, executor_class, log_stats,
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 77, in __init__
ERROR 08-08 12:18:45 [core.py:632]     self.model_executor = executor_class(vllm_config)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
ERROR 08-08 12:18:45 [core.py:632]     self._init_executor()
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
ERROR 08-08 12:18:45 [core.py:632]     self.collective_rpc("init_device")
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
ERROR 08-08 12:18:45 [core.py:632]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/utils/__init__.py", line 2985, in run_method
ERROR 08-08 12:18:45 [core.py:632]     return func(*args, **kwargs)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 603, in init_device
ERROR 08-08 12:18:45 [core.py:632]     self.worker.init_device()  # type: ignore
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 189, in init_device
ERROR 08-08 12:18:45 [core.py:632]     self.model_runner: GPUModelRunner = GPUModelRunner(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 146, in __init__
ERROR 08-08 12:18:45 [core.py:632]     encoder_compute_budget, encoder_cache_size = compute_encoder_budget(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/core/encoder_cache_manager.py", line 199, in compute_encoder_budget
ERROR 08-08 12:18:45 [core.py:632]     ) = _compute_encoder_budget_multimodal(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/core/encoder_cache_manager.py", line 229, in _compute_encoder_budget_multimodal
ERROR 08-08 12:18:45 [core.py:632]     .get_max_tokens_per_item_by_nonzero_modality(model_config)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 158, in get_max_tokens_per_item_by_nonzero_modality
ERROR 08-08 12:18:45 [core.py:632]     self.get_max_tokens_per_item_by_modality(model_config).items()
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 132, in get_max_tokens_per_item_by_modality
ERROR 08-08 12:18:45 [core.py:632]     return profiler.get_mm_max_tokens(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 287, in get_mm_max_tokens
ERROR 08-08 12:18:45 [core.py:632]     mm_inputs = self._get_dummy_mm_inputs(seq_len, mm_counts)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 170, in _get_dummy_mm_inputs
ERROR 08-08 12:18:45 [core.py:632]     processor_inputs = factory.get_dummy_processor_inputs(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 92, in get_dummy_processor_inputs
ERROR 08-08 12:18:45 [core.py:632]     dummy_text = self.get_dummy_text(mm_counts)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/model_executor/models/llava.py", line 192, in get_dummy_text
ERROR 08-08 12:18:45 [core.py:632]     processor = self.info.get_hf_processor()
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/model_executor/models/llava.py", line 288, in get_hf_processor
ERROR 08-08 12:18:45 [core.py:632]     return self.ctx.get_hf_processor(PixtralProcessor, **kwargs)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/inputs/registry.py", line 138, in get_hf_processor
ERROR 08-08 12:18:45 [core.py:632]     return super().get_hf_processor(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/inputs/registry.py", line 101, in get_hf_processor
ERROR 08-08 12:18:45 [core.py:632]     return cached_processor_from_config(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 110, in cached_processor_from_config
ERROR 08-08 12:18:45 [core.py:632]     return cached_get_processor(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 72, in get_processor
ERROR 08-08 12:18:45 [core.py:632]     processor = processor_factory.from_pretrained(
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/transformers/processing_utils.py", line 1314, in from_pretrained
ERROR 08-08 12:18:45 [core.py:632]     return cls.from_args_and_dict(args, processor_dict, **kwargs)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/transformers/processing_utils.py", line 1115, in from_args_and_dict
ERROR 08-08 12:18:45 [core.py:632]     processor = cls(*args, **valid_kwargs)
ERROR 08-08 12:18:45 [core.py:632]   File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/transformers/models/pixtral/processing_pixtral.py", line 110, in __init__
ERROR 08-08 12:18:45 [core.py:632]     self.image_token_id = tokenizer.convert_tokens_to_ids(self.image_token)
ERROR 08-08 12:18:45 [core.py:632] AttributeError: 'MistralTokenizer' object has no attribute 'convert_tokens_to_ids'. Did you mean: 'convert_tokens_to_string'?
Process EngineCore_0:
Traceback (most recent call last):
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 636, in run_engine_core
    raise e
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 623, in run_engine_core
    engine_core = EngineCoreProc(*args, **kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 441, in __init__
    super().__init__(vllm_config, executor_class, log_stats,
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 77, in __init__
    self.model_executor = executor_class(vllm_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
    self._init_executor()
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
    self.collective_rpc("init_device")
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/utils/__init__.py", line 2985, in run_method
    return func(*args, **kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 603, in init_device
    self.worker.init_device()  # type: ignore
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 189, in init_device
    self.model_runner: GPUModelRunner = GPUModelRunner(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 146, in __init__
    encoder_compute_budget, encoder_cache_size = compute_encoder_budget(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/core/encoder_cache_manager.py", line 199, in compute_encoder_budget
    ) = _compute_encoder_budget_multimodal(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/core/encoder_cache_manager.py", line 229, in _compute_encoder_budget_multimodal
    .get_max_tokens_per_item_by_nonzero_modality(model_config)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 158, in get_max_tokens_per_item_by_nonzero_modality
    self.get_max_tokens_per_item_by_modality(model_config).items()
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 132, in get_max_tokens_per_item_by_modality
    return profiler.get_mm_max_tokens(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 287, in get_mm_max_tokens
    mm_inputs = self._get_dummy_mm_inputs(seq_len, mm_counts)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 170, in _get_dummy_mm_inputs
    processor_inputs = factory.get_dummy_processor_inputs(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 92, in get_dummy_processor_inputs
    dummy_text = self.get_dummy_text(mm_counts)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/model_executor/models/llava.py", line 192, in get_dummy_text
    processor = self.info.get_hf_processor()
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/model_executor/models/llava.py", line 288, in get_hf_processor
    return self.ctx.get_hf_processor(PixtralProcessor, **kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/inputs/registry.py", line 138, in get_hf_processor
    return super().get_hf_processor(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/inputs/registry.py", line 101, in get_hf_processor
    return cached_processor_from_config(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 110, in cached_processor_from_config
    return cached_get_processor(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 72, in get_processor
    processor = processor_factory.from_pretrained(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/transformers/processing_utils.py", line 1314, in from_pretrained
    return cls.from_args_and_dict(args, processor_dict, **kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/transformers/processing_utils.py", line 1115, in from_args_and_dict
    processor = cls(*args, **valid_kwargs)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/transformers/models/pixtral/processing_pixtral.py", line 110, in __init__
    self.image_token_id = tokenizer.convert_tokens_to_ids(self.image_token)
AttributeError: 'MistralTokenizer' object has no attribute 'convert_tokens_to_ids'. Did you mean: 'convert_tokens_to_string'?
[rank0]:[W808 12:18:45.924018513 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/Pixtral-Finetune/inference_scripts/all_experiments_mistral.py", line 311, in <module>
    llm = LLM(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/entrypoints/llm.py", line 273, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 497, in from_engine_args
    return engine_cls.from_vllm_config(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py", line 126, in from_vllm_config
    return cls(vllm_config=vllm_config,
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py", line 103, in __init__
    self.engine_core = EngineCoreClient.make_client(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 77, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 514, in __init__
    super().__init__(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 408, in __init__
    with launch_core_engines(vllm_config, executor_class,
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 697, in launch_core_engines
    wait_for_engine_startup(
  File "/pfs/work9/workspace/scratch/ul_swv79-pixtral/conda/pixtral/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 750, in wait_for_engine_startup
    raise RuntimeError("Engine core initialization failed. "
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

============================= JOB FEEDBACK =============================

NodeName=uc3n082
Job ID: 1094231
Cluster: uc3
User/Group: ul_swv79/ul_student
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 8
CPU Utilized: 00:00:31
CPU Efficiency: 3.99% of 00:12:56 core-walltime
Job Wall-clock time: 00:01:37
Memory Utilized: 1.40 GB
Memory Efficiency: 2.19% of 64.00 GB (64.00 GB/node)
